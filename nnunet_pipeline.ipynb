{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb5e05e",
   "metadata": {},
   "source": [
    "# nnU-Net Pipeline Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a1b8a",
   "metadata": {},
   "source": [
    "This notebook replicates the end-to-end nnU-Net pipeline (data preparation, training, inference) in three separate stages.\n",
    "Update the configuration cell, then execute the subsequent sections sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af11878",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e5c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe433ef",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Edit the fields of `PipelineConfig` or override `cfg` attributes after instantiation to match your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea070cd-23ab-408c-85c2-7fadb4fd43b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using trainer: nnUNetTrainer\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Trainer mapping (add your custom trainers here)\n",
    "# ----------------------------------------------------------------------\n",
    "TRAINER_MAP = {\n",
    "    \"default\": \"nnUNetTrainer\",                           # Baseline trainer\n",
    "    \"da5\": \"nnUNetTrainerDA5\",                            # DA5 with advanced augmentations\n",
    "    \"nomirror\": \"nnUNetTrainerNoMirroring\",               # No mirror augmentation\n",
    "    \"cedice300\": \"nnUNetTrainerNoMirroring_CEDice300\",    # CE + Dice (300 epochs)\n",
    "    \"focaldice300\": \"nnUNetTrainerNoMirroring_FocalDice300\",  # Focal + Dice (300 epochs)\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    # ---------------- Basic Settings ----------------\n",
    "    data_root: Path = field(default_factory=lambda: Path(\"public_leaderboard_data\"))\n",
    "    dataset_id: int = 500\n",
    "    dataset_name: str = \"AbdominalCTMultiOrgan\"\n",
    "\n",
    "    nnunet_raw: Path = field(default_factory=lambda: Path(\"./nnUNet_raw\"))\n",
    "    nnunet_preprocessed: Path = field(default_factory=lambda: Path(\"./nnUNet_preprocessed\"))\n",
    "    nnunet_results: Path = field(default_factory=lambda: Path(\"./nnUNet_results\"))\n",
    "\n",
    "    configurations: Sequence[str] = (\"3d_fullres\",)\n",
    "\n",
    "    # ---------------- Trainer Variant ----------------\n",
    "    # Choices: \"default\", \"da5\", \"nomirror\", \"cedice300\", \"focaldice300\"\n",
    "    trainer_variant: str = \"default\"\n",
    "\n",
    "    # Trainer class will be populated automatically based on trainer_variant\n",
    "    trainer_class: str = \"\"\n",
    "\n",
    "    # ---------------- nnU-Net Internal Config ----------------\n",
    "    plans_identifier: str = \"nnUNetResEncUNetMPlans\"\n",
    "    fold: str = \"all\"\n",
    "    device: str = \"cuda\"\n",
    "    num_gpus: int = 1\n",
    "\n",
    "    num_processes_fingerprint: int = 4\n",
    "    num_processes_preprocess: int = 4\n",
    "\n",
    "    checkpoint_name: str = \"checkpoint_best.pth\"\n",
    "    planner_class: str = \"nnUNetPlannerResEncM\"\n",
    "\n",
    "    gpu_memory_target: Optional[float] = None\n",
    "    preprocessor_class: str = \"DefaultPreprocessor\"\n",
    "\n",
    "    # ---------------- Flags for skipping pipeline stages ----------------\n",
    "    verify_dataset: bool = False\n",
    "    skip_conversion: bool = False\n",
    "    skip_preprocessing: bool = False\n",
    "    skip_training: bool = False\n",
    "    skip_validation_inference: bool = False\n",
    "    skip_test_inference: bool = False\n",
    "\n",
    "    # ---------------- Output Settings ----------------\n",
    "    prediction_output: Optional[Path] = None\n",
    "    export_test_pngs: bool = True\n",
    "    png_output_root: Optional[Path] = None\n",
    "    overwrite: bool = False\n",
    "    save_probabilities: bool = False\n",
    "    export_validation_probabilities: bool = False\n",
    "\n",
    "    inference_preprocess_workers: int = 1\n",
    "    inference_export_workers: int = 0\n",
    "    bounding_box_prompts: Optional[Path] = None\n",
    "    only_configuration: Optional[str] = None\n",
    "    log_to_stdout: bool = True\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"Resolve trainer class and ensure prediction output path exists.\"\"\"\n",
    "        \n",
    "        # 1. Set trainer class based on selected variant\n",
    "        if self.trainer_variant not in TRAINER_MAP:\n",
    "            raise ValueError(f\"Invalid trainer_variant '{self.trainer_variant}'. \"\n",
    "                             f\"Choose from: {list(TRAINER_MAP.keys())}\")\n",
    "\n",
    "        self.trainer_class = TRAINER_MAP[self.trainer_variant]\n",
    "\n",
    "        # 2. Setup prediction output folder\n",
    "        if self.prediction_output is None:\n",
    "            self.prediction_output = Path(\"./notebook_predictions\")\n",
    "        else:\n",
    "            self.prediction_output = Path(self.prediction_output)\n",
    "\n",
    "        self.prediction_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def clone(self) -> \"PipelineConfig\":\n",
    "        return PipelineConfig(**self.__dict__)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Usage Example\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Example 1: Default nnUNetTrainer\n",
    "# cfg = PipelineConfig(trainer_variant=\"default\").finalize()\n",
    "# print(\"Using trainer:\", cfg.trainer_class)\n",
    "\n",
    "# Example 2: CE + Dice (300 epochs)\n",
    "# cfg = PipelineConfig(trainer_variant=\"cedice300\").finalize()\n",
    "# print(\"Using trainer:\", cfg.trainer_class)\n",
    "\n",
    "# Example 3: Focal + Dice (300 epochs)\n",
    "cfg = PipelineConfig(trainer_variant=\"focaldice300\").finalize()\n",
    "print(\"Using trainer:\", cfg.trainer_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cf5e1",
   "metadata": {},
   "source": [
    "## Utility Functions & Dataset Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb246063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "\n",
    "def configure_environment(cfg: PipelineConfig) -> None:\n",
    "    os.environ.setdefault(\"nnUNet_raw\", str(cfg.nnunet_raw.resolve()))\n",
    "    os.environ.setdefault(\"nnUNet_preprocessed\", str(cfg.nnunet_preprocessed.resolve()))\n",
    "    os.environ.setdefault(\"nnUNet_results\", str(cfg.nnunet_results.resolve()))\n",
    "    for root in (cfg.nnunet_raw, cfg.nnunet_preprocessed, cfg.nnunet_results):\n",
    "        Path(root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def ensure_dependencies() -> None:\n",
    "    try:\n",
    "        import torch  # noqa: F401\n",
    "    except ImportError as exc:\n",
    "        raise RuntimeError(\"PyTorch is required to run the pipeline. Install project dependencies first.\") from exc\n",
    "\n",
    "\n",
    "def parse_spacing_map(spacing_file: Path) -> Dict[str, Tuple[float, float, float]]:\n",
    "    if not spacing_file.exists():\n",
    "        raise FileNotFoundError(f\"Spacing file not found: {spacing_file}\")\n",
    "    mapping: Dict[str, Tuple[float, float, float]] = {}\n",
    "    with spacing_file.open(\"r\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            if \":\" not in line:\n",
    "                continue\n",
    "            key, value = line.split(\":\", 1)\n",
    "            case_id = key.strip().zfill(2)\n",
    "            spacing = eval(value.strip(), {\"__builtins__\": {}})\n",
    "            if not isinstance(spacing, (list, tuple)) or len(spacing) != 3:\n",
    "                raise ValueError(f\"Unexpected spacing entry for case {case_id}: {value}\")\n",
    "            mapping[case_id] = tuple(float(v) for v in spacing)\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def sorted_slice_paths(case_folder: Path) -> List[Path]:\n",
    "    slices = sorted(case_folder.glob(\"*.png\"), key=lambda p: int(p.stem))\n",
    "    if not slices:\n",
    "        raise FileNotFoundError(f\"No PNG slices found in {case_folder}\")\n",
    "    return slices\n",
    "\n",
    "\n",
    "def load_stack(slice_paths: Sequence[Path]) -> np.ndarray:\n",
    "    stack = [io.imread(str(p)) for p in slice_paths]\n",
    "    return np.stack(stack, axis=0)\n",
    "\n",
    "\n",
    "def write_nifti(volume: np.ndarray, spacing: Tuple[float, float, float], output_path: Path, dtype: np.dtype) -> None:\n",
    "    img = sitk.GetImageFromArray(volume.astype(dtype, copy=False))\n",
    "    img.SetSpacing(tuple(float(v) for v in spacing))\n",
    "    img.SetOrigin((0.0, 0.0, 0.0))\n",
    "    img.SetDirection((1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0))\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sitk.WriteImage(img, str(output_path))\n",
    "\n",
    "\n",
    "def convert_split_to_nnunet(\n",
    "    case_ids: Iterable[str],\n",
    "    image_root: Path,\n",
    "    label_root: Optional[Path],\n",
    "    output_images: Path,\n",
    "    output_labels: Optional[Path],\n",
    "    spacing_map: Dict[str, Tuple[float, float, float]],\n",
    "    prefix: str,\n",
    "    overwrite: bool,\n",
    ") -> Tuple[List[str], Dict[str, str]]:\n",
    "    case_identifiers: List[str] = []\n",
    "    case_mapping: Dict[str, str] = {}\n",
    "    for case_id in sorted(case_ids, key=lambda x: int(x)):\n",
    "        image_case_dir = image_root / case_id\n",
    "        label_case_dir = label_root / case_id if label_root is not None else None\n",
    "        if not image_case_dir.is_dir():\n",
    "            raise FileNotFoundError(f\"Missing image folder for case {case_id}: {image_case_dir}\")\n",
    "        spacing = spacing_map.get(case_id)\n",
    "        if spacing is None:\n",
    "            raise KeyError(f\"No spacing metadata for case {case_id} in spacing file\")\n",
    "        case_name = f\"{prefix}_{case_id.zfill(3)}\"\n",
    "        image_output_path = output_images / f\"{case_name}_0000.nii.gz\"\n",
    "        if image_output_path.exists() and not overwrite:\n",
    "            case_identifiers.append(case_name)\n",
    "            case_mapping[case_name] = str(case_id).zfill(2)\n",
    "            continue\n",
    "        slices = sorted_slice_paths(image_case_dir)\n",
    "        volume = load_stack(slices).astype(np.int16, copy=False)\n",
    "        write_nifti(volume, spacing, image_output_path, np.int16)\n",
    "        if label_case_dir is not None:\n",
    "            if output_labels is None:\n",
    "                raise ValueError(\"Label root provided but output label directory missing.\")\n",
    "            label_slices = sorted_slice_paths(label_case_dir)\n",
    "            if len(label_slices) != len(slices):\n",
    "                raise ValueError(\n",
    "                    f\"Mismatched slice count for case {case_id}: {len(slices)} images vs {len(label_slices)} labels\"\n",
    "                )\n",
    "            label_volume = load_stack(label_slices).astype(np.uint8, copy=False)\n",
    "            label_output_path = output_labels / f\"{case_name}.nii.gz\"\n",
    "            write_nifti(label_volume, spacing, label_output_path, np.uint8)\n",
    "        case_identifiers.append(case_name)\n",
    "        case_mapping[case_name] = str(case_id).zfill(2)\n",
    "    return case_identifiers, case_mapping\n",
    "\n",
    "\n",
    "def parse_bbox_prompts(bbox_file: Optional[Path], output_json: Path) -> None:\n",
    "    if not bbox_file or not bbox_file.exists():\n",
    "        return\n",
    "    prompts: Dict[str, Dict[str, Dict[str, Sequence[int]]]] = {}\n",
    "    with bbox_file.open(\"r\") as f:\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if not line.startswith(\"<\") or \">:\" not in line:\n",
    "                continue\n",
    "            key, value = line.split(\">:\")\n",
    "            triplet = key.strip(\"<>\").split(\",\")\n",
    "            if len(triplet) != 3:\n",
    "                continue\n",
    "            case_id = triplet[0].strip().zfill(2)\n",
    "            slice_idx = triplet[1].strip()\n",
    "            organ_idx = triplet[2].strip()\n",
    "            coords = eval(value.strip(), {\"__builtins__\": {}})\n",
    "            prompts.setdefault(case_id, {}).setdefault(slice_idx, {})[organ_idx] = coords\n",
    "    output_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with output_json.open(\"w\") as f:\n",
    "        json.dump(prompts, f, indent=2)\n",
    "\n",
    "\n",
    "def generate_dataset_json_file(\n",
    "    dataset_dir: Path,\n",
    "    num_training_cases: int,\n",
    "    labels: Dict[str, int],\n",
    "    dataset_name: str,\n",
    "    metadata: Dict[str, object],\n",
    ") -> None:\n",
    "    generate_dataset_json(\n",
    "        str(dataset_dir),\n",
    "        channel_names={0: \"CT\"},\n",
    "        labels=labels,\n",
    "        num_training_cases=num_training_cases,\n",
    "        file_ending=\".nii.gz\",\n",
    "        dataset_name=dataset_name,\n",
    "        **metadata,\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_raw_dataset(cfg: PipelineConfig, dataset_dir: Path) -> Tuple[Dict[str, List[str]], Dict[str, str]]:\n",
    "    spacing_map = parse_spacing_map(cfg.data_root / \"spacing_mm.txt\")\n",
    "    train_ids = [p.name for p in (cfg.data_root / \"train_images\").iterdir() if p.is_dir()]\n",
    "    val_ids = [p.name for p in (cfg.data_root / \"val_images\").iterdir() if p.is_dir()]\n",
    "    test_ids = [p.name for p in (cfg.data_root / \"test1_images\").iterdir() if p.is_dir()]\n",
    "\n",
    "    images_tr = dataset_dir / \"imagesTr\"\n",
    "    labels_tr = dataset_dir / \"labelsTr\"\n",
    "    images_ts = dataset_dir / \"imagesTs\"\n",
    "    images_tr.mkdir(parents=True, exist_ok=True)\n",
    "    labels_tr.mkdir(parents=True, exist_ok=True)\n",
    "    images_ts.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_cases, train_map = convert_split_to_nnunet(\n",
    "        train_ids,\n",
    "        cfg.data_root / \"train_images\",\n",
    "        cfg.data_root / \"train_labels\",\n",
    "        images_tr,\n",
    "        labels_tr,\n",
    "        spacing_map,\n",
    "        prefix=\"ct\",\n",
    "        overwrite=cfg.overwrite,\n",
    "    )\n",
    "    val_cases, val_map = convert_split_to_nnunet(\n",
    "        val_ids,\n",
    "        cfg.data_root / \"val_images\",\n",
    "        cfg.data_root / \"val_labels\",\n",
    "        images_tr,\n",
    "        labels_tr,\n",
    "        spacing_map,\n",
    "        prefix=\"ct\",\n",
    "        overwrite=cfg.overwrite,\n",
    "    )\n",
    "    test_cases, test_map = convert_split_to_nnunet(\n",
    "        test_ids,\n",
    "        cfg.data_root / \"test1_images\",\n",
    "        None,\n",
    "        images_ts,\n",
    "        None,\n",
    "        spacing_map,\n",
    "        prefix=\"ct\",\n",
    "        overwrite=cfg.overwrite,\n",
    "    )\n",
    "\n",
    "    metadata = {\n",
    "        \"training_cases\": train_cases,\n",
    "        \"validation_cases\": val_cases,\n",
    "        \"test_cases\": test_cases,\n",
    "        \"spacing_file\": str((cfg.data_root / \"spacing_mm.txt\").resolve()),\n",
    "        \"case_folder_map\": {**train_map, **val_map, **test_map},\n",
    "    }\n",
    "\n",
    "    labels = {\"background\": 0}\n",
    "    for organ_idx in range(1, 13):\n",
    "        labels[f\"organ_{organ_idx:02d}\"] = organ_idx\n",
    "\n",
    "    generate_dataset_json_file(\n",
    "        dataset_dir=dataset_dir,\n",
    "        num_training_cases=len(train_cases) + len(val_cases),\n",
    "        labels=labels,\n",
    "        dataset_name=dataset_dir.name,\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "    splits = [{\"train\": train_cases, \"val\": val_cases}]\n",
    "    splits_file = dataset_dir / \"splits_final.json\"\n",
    "    if not splits_file.exists() or cfg.overwrite:\n",
    "        with splits_file.open(\"w\") as f:\n",
    "            json.dump(splits, f, indent=2)\n",
    "\n",
    "    if cfg.bounding_box_prompts:\n",
    "        parse_bbox_prompts(cfg.bounding_box_prompts, dataset_dir / \"test_bboxes.json\")\n",
    "\n",
    "    return {\"train\": train_cases, \"val\": val_cases, \"test\": test_cases}, {**train_map, **val_map, **test_map}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc9abe",
   "metadata": {},
   "source": [
    "## Training & Inference Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0d6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_planning_and_preprocessing(cfg: PipelineConfig, configurations: Sequence[str]) -> str:\n",
    "    from nnunetv2.experiment_planning.plan_and_preprocess_api import (\n",
    "        extract_fingerprints,\n",
    "        plan_experiments,\n",
    "        preprocess,\n",
    "    )\n",
    "\n",
    "    dataset_ids = [cfg.dataset_id]\n",
    "    extract_fingerprints(\n",
    "        dataset_ids,\n",
    "        num_processes=cfg.num_processes_fingerprint,\n",
    "        check_dataset_integrity=cfg.verify_dataset,\n",
    "        clean=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    resulting = plan_experiments(\n",
    "        dataset_ids,\n",
    "        experiment_planner_class_name=cfg.planner_class,\n",
    "        preprocess_class_name=cfg.preprocessor_class,\n",
    "        gpu_memory_target_in_gb=cfg.gpu_memory_target,\n",
    "    )\n",
    "    preprocess(\n",
    "        dataset_ids,\n",
    "        plans_identifier=resulting or cfg.plans_identifier,\n",
    "        configurations=tuple(configurations),\n",
    "        num_processes=tuple([cfg.num_processes_preprocess] * len(configurations)),\n",
    "        verbose=True,\n",
    "    )\n",
    "    return resulting or cfg.plans_identifier\n",
    "\n",
    "\n",
    "def build_model_output_dir(dataset_name: str, trainer_class: str, plans_identifier: str, configuration: str) -> Path:\n",
    "    base = Path(os.environ[\"nnUNet_results\"])\n",
    "    return base / dataset_name / f\"{trainer_class}__{plans_identifier}__{configuration}\"\n",
    "\n",
    "\n",
    "def run_training_stage(\n",
    "    cfg: PipelineConfig,\n",
    "    dataset_name: str,\n",
    "    configuration: str,\n",
    "    plans_identifier: str,\n",
    ") -> None:\n",
    "    import torch\n",
    "    from nnunetv2.run.run_training import run_training\n",
    "\n",
    "    torch_device = torch.device(cfg.device)\n",
    "    run_training(\n",
    "        dataset_name,\n",
    "        configuration=configuration,\n",
    "        fold=cfg.fold,\n",
    "        trainer_class_name=cfg.trainer_class,\n",
    "        plans_identifier=plans_identifier,\n",
    "        num_gpus=cfg.num_gpus,\n",
    "        device=torch_device,\n",
    "        export_validation_probabilities=cfg.export_validation_probabilities,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    model_dir: Path,\n",
    "    fold: str,\n",
    "    inputs: Sequence[List[str]],\n",
    "    output_dir: Path,\n",
    "    device: str,\n",
    "    checkpoint_name: str,\n",
    "    save_probabilities: bool,\n",
    "    overwrite: bool,\n",
    "    num_preprocess_workers: int,\n",
    "    num_export_workers: int,\n",
    ") -> None:\n",
    "    import gc\n",
    "    import torch\n",
    "    from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "\n",
    "    predictor = nnUNetPredictor(\n",
    "        tile_step_size=0.5,\n",
    "        use_gaussian=True,\n",
    "        use_mirroring=False,\n",
    "        perform_everything_on_device=True,\n",
    "        device=torch.device(device),\n",
    "        verbose=False,\n",
    "        verbose_preprocessing=False,\n",
    "        allow_tqdm=True\n",
    "    )\n",
    "    predictor.initialize_from_trained_model_folder(str(model_dir), use_folds=(fold,), checkpoint_name=checkpoint_name)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    preprocess_workers = max(1, num_preprocess_workers)\n",
    "    export_workers = max(0, num_export_workers)\n",
    "    input_batches = list(inputs)\n",
    "\n",
    "    if export_workers == 0:\n",
    "        predictor.predict_from_files_sequential(\n",
    "            input_batches,\n",
    "            str(output_dir),\n",
    "            save_probabilities=save_probabilities,\n",
    "            overwrite=overwrite,\n",
    "        )\n",
    "    else:\n",
    "        predictor.predict_from_files(\n",
    "            input_batches,\n",
    "            str(output_dir),\n",
    "            save_probabilities=save_probabilities,\n",
    "            overwrite=overwrite,\n",
    "            num_processes_preprocessing=preprocess_workers,\n",
    "            num_processes_segmentation_export=export_workers,\n",
    "        )\n",
    "\n",
    "    gc.collect()\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def compute_validation_metrics(\n",
    "    predictions_dir: Path,\n",
    "    dataset_dir: Path,\n",
    "    plans_identifier: str,\n",
    "    output_filename: Optional[Path] = None,\n",
    ") -> Dict[str, object]:\n",
    "    from nnunetv2.evaluation.evaluate_predictions import compute_metrics_on_folder2\n",
    "\n",
    "    dataset_json = dataset_dir / \"dataset.json\"\n",
    "    plans_file = Path(os.environ[\"nnUNet_preprocessed\"]) / dataset_dir.name / f\"{plans_identifier}.json\"\n",
    "    gt_folder = dataset_dir / \"labelsTr\"\n",
    "    return compute_metrics_on_folder2(\n",
    "        str(gt_folder),\n",
    "        str(predictions_dir),\n",
    "        str(dataset_json),\n",
    "        str(plans_file),\n",
    "        output_file=str(output_filename) if output_filename else None,\n",
    "        chill=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_inference_input_lists(image_dir: Path, case_ids: Sequence[str], file_ending: str) -> List[List[str]]:\n",
    "    inputs: List[List[str]] = []\n",
    "    for case in case_ids:\n",
    "        image_file = image_dir / f\"{case}_0000{file_ending}\"\n",
    "        if not image_file.exists():\n",
    "            raise FileNotFoundError(f\"Missing input volume for inference: {image_file}\")\n",
    "        inputs.append([str(image_file)])\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def convert_nifti_to_png_slices(nifti_file: Path, output_dir: Path) -> None:\n",
    "    img = sitk.ReadImage(str(nifti_file))\n",
    "    data = sitk.GetArrayFromImage(img).astype(np.uint8, copy=False)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for idx, slice_arr in enumerate(data, start=1):\n",
    "        slice_path = output_dir / f\"{idx}.png\"\n",
    "        io.imsave(str(slice_path), slice_arr, check_contrast=False)\n",
    "\n",
    "\n",
    "def export_predictions_to_png(\n",
    "    predictions_dir: Path,\n",
    "    output_root: Path,\n",
    "    case_folder_map: Dict[str, str],\n",
    ") -> None:\n",
    "    prediction_files = sorted(predictions_dir.glob(\"*.nii.gz\"))\n",
    "    if not prediction_files:\n",
    "        return\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    for prediction_file in prediction_files:\n",
    "        filename = prediction_file.name\n",
    "        identifier = filename[:-7] if filename.endswith(\".nii.gz\") else prediction_file.stem\n",
    "        folder_name = case_folder_map.get(identifier, identifier.split(\"_\")[-1])\n",
    "        folder_name = str(int(folder_name)).zfill(2) if folder_name.isdigit() else folder_name\n",
    "        convert_nifti_to_png_slices(prediction_file, output_root / folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2f9cd",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Run this cell to convert the PNG slices into the nnU-Net raw data structure (unless skipped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e42cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dataset stored at /workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['ct_001',\n",
       "  'ct_002',\n",
       "  'ct_003',\n",
       "  'ct_004',\n",
       "  'ct_005',\n",
       "  'ct_006',\n",
       "  'ct_007',\n",
       "  'ct_008',\n",
       "  'ct_009',\n",
       "  'ct_010',\n",
       "  'ct_011',\n",
       "  'ct_012',\n",
       "  'ct_013',\n",
       "  'ct_014',\n",
       "  'ct_015',\n",
       "  'ct_016',\n",
       "  'ct_017',\n",
       "  'ct_018',\n",
       "  'ct_019',\n",
       "  'ct_020',\n",
       "  'ct_021',\n",
       "  'ct_022',\n",
       "  'ct_023',\n",
       "  'ct_024',\n",
       "  'ct_025',\n",
       "  'ct_026',\n",
       "  'ct_027',\n",
       "  'ct_028',\n",
       "  'ct_029',\n",
       "  'ct_030',\n",
       "  'ct_031',\n",
       "  'ct_032',\n",
       "  'ct_033',\n",
       "  'ct_034',\n",
       "  'ct_035',\n",
       "  'ct_036',\n",
       "  'ct_037',\n",
       "  'ct_038',\n",
       "  'ct_039',\n",
       "  'ct_040'],\n",
       " 'val': ['ct_041',\n",
       "  'ct_042',\n",
       "  'ct_043',\n",
       "  'ct_044',\n",
       "  'ct_045',\n",
       "  'ct_046',\n",
       "  'ct_047',\n",
       "  'ct_048',\n",
       "  'ct_049',\n",
       "  'ct_050'],\n",
       " 'test': ['ct_051',\n",
       "  'ct_052',\n",
       "  'ct_053',\n",
       "  'ct_054',\n",
       "  'ct_055',\n",
       "  'ct_056',\n",
       "  'ct_057',\n",
       "  'ct_058',\n",
       "  'ct_059',\n",
       "  'ct_060',\n",
       "  'ct_061',\n",
       "  'ct_062',\n",
       "  'ct_063',\n",
       "  'ct_064',\n",
       "  'ct_065']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "configure_environment(cfg)\n",
    "ensure_dependencies()\n",
    "\n",
    "dataset_name = f\"Dataset{cfg.dataset_id:03d}_{cfg.dataset_name}\"\n",
    "dataset_dir = Path(os.environ[\"nnUNet_raw\"]) / dataset_name\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if cfg.skip_conversion and (dataset_dir / \"dataset.json\").exists():\n",
    "    with (dataset_dir / \"dataset.json\").open(\"r\") as f:\n",
    "        dataset_meta = json.load(f)\n",
    "    case_splits = {\n",
    "        \"train\": dataset_meta.get(\"training_cases\", []),\n",
    "        \"val\": dataset_meta.get(\"validation_cases\", []),\n",
    "        \"test\": dataset_meta.get(\"test_cases\", []),\n",
    "    }\n",
    "    raw_map = dataset_meta.get(\"case_folder_map\", {}) or {}\n",
    "    case_folder_map = {k: str(v).zfill(2) for k, v in raw_map.items()}\n",
    "    if cfg.log_to_stdout:\n",
    "        print(\"Skipping dataset conversion (dataset.json already present).\")\n",
    "else:\n",
    "    case_splits, case_folder_map = prepare_raw_dataset(cfg, dataset_dir)\n",
    "    if cfg.log_to_stdout:\n",
    "        print(f\"Converted dataset stored at {dataset_dir}\")\n",
    "\n",
    "if not case_folder_map:\n",
    "    case_folder_map = {identifier: identifier.split(\"_\")[-1] for identifier in case_splits.get(\"test\", [])}\n",
    "\n",
    "active_configurations = list((cfg.only_configuration,) if cfg.only_configuration else cfg.configurations)\n",
    "case_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1f8f0",
   "metadata": {},
   "source": [
    "## Training\n",
    "Preprocess the dataset and train the requested configurations/folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6f692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset500_AbdominalCTMultiOrgan\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.81776386 0.81776386]. \n",
      "Current patch size: (np.int64(40), np.int64(224), np.int64(192)). \n",
      "Current median shape: [ 97.         497.08737864 497.08737864]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.84229677 0.84229677]. \n",
      "Current patch size: (np.int64(40), np.int64(224), np.int64(192)). \n",
      "Current median shape: [ 97.         482.60910548 482.60910548]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.86756567 0.86756567]. \n",
      "Current patch size: (np.int64(40), np.int64(224), np.int64(192)). \n",
      "Current median shape: [ 97.         468.55252959 468.55252959]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.89359265 0.89359265]. \n",
      "Current patch size: (np.int64(40), np.int64(224), np.int64(192)). \n",
      "Current median shape: [ 97.         454.90536853 454.90536853]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.92040042 0.92040042]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.        441.6556976 441.6556976]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.94801244 0.94801244]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         428.79193942 428.79193942]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        0.97645281 0.97645281]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         416.30285381 416.30285381]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.00574639 1.00574639]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         404.17752797 404.17752797]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.03591879 1.03591879]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         392.40536696 392.40536696]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.06699635 1.06699635]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         380.97608443 380.97608443]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.09900624 1.09900624]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         369.87969362 369.87969362]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.13197643 1.13197643]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         359.10649866 359.10649866]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.16593572 1.16593572]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         348.64708608 348.64708608]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.20091379 1.20091379]. \n",
      "Current patch size: (np.int64(48), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         338.49231658 338.49231658]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.23694121 1.23694121]. \n",
      "Current patch size: (np.int64(56), np.int64(192), np.int64(160)). \n",
      "Current median shape: [ 97.         328.63331707 328.63331707]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.5        1.27404944 1.27404944]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 97.         319.06147288 319.06147288]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.575      1.31227093 1.31227093]. \n",
      "Current patch size: (np.int64(64), np.int64(192), np.int64(192)). \n",
      "Current median shape: [ 94.17475728 309.76842027 309.76842027]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': (np.int64(512), np.int64(512)), 'median_image_size_in_voxels': array([512., 512.]), 'spacing': array([0.79394549, 0.79394549]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetResEncUNetMPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(192), np.int64(192)), 'median_image_size_in_voxels': (94, 310, 310), 'spacing': array([2.575     , 1.31227093, 1.31227093]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(40), np.int64(224), np.int64(192)), 'median_image_size_in_voxels': array([ 97., 512., 512.]), 'spacing': array([2.5       , 0.79394549, 0.79394549]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to /workspace/nnUNet_preprocessed/Dataset500_AbdominalCTMultiOrgan/nnUNetResEncUNetMPlans.json\n",
      "Preprocessing dataset Dataset500_AbdominalCTMultiOrgan\n",
      "Configuration: 3d_fullres...\n",
      "Preprocessing the following configuration: 3d_fullres\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 192], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7939454913139343, 0.7939454913139343], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_003.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_002.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_004.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_001.nii.gz\n",
      "old shape: (107, 512, 512), new_shape: [107 479 479], old_spacing: [np.float64(2.5), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 3004\n",
      "6 4131\n",
      "7 11622\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (103, 512, 512), new_shape: [103 586 586], old_spacing: [np.float64(2.5), np.float64(0.9082030057907104), np.float64(0.9082030057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2420\n",
      "6 2948\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (87, 512, 512), new_shape: [104 540 540], old_spacing: [np.float64(3.0), np.float64(0.837890625), np.float64(0.837890625)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9309\n",
      "4 10000\n",
      "5 2347\n",
      "6 3433\n",
      "7 10287\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (129, 512, 512), new_shape: [129 630 630], old_spacing: [np.float64(2.5), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 7434\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 3191\n",
      "6 2292\n",
      "7 13966\n",
      "8 10000\n",
      "9 10000\n",
      "10 19606\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_005.nii.gz\n",
      "old shape: (98, 512, 512), new_shape: [ 98 529 529], old_spacing: [np.float64(2.5), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 7805\n",
      "4 10000\n",
      "5 2185\n",
      "6 3168\n",
      "7 11678\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_006.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_007.nii.gz\n",
      "old shape: (92, 512, 512), new_shape: [ 92 511 511], old_spacing: [np.float64(2.5), np.float64(0.7929689884185791), np.float64(0.7929689884185791)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9356\n",
      "4 10000\n",
      "5 3761\n",
      "6 4549\n",
      "7 12436\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (93, 512, 512), new_shape: [ 93 539 539], old_spacing: [np.float64(2.5), np.float64(0.8359379768371582), np.float64(0.8359379768371582)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2060\n",
      "6 3071\n",
      "7 11070\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_008.nii.gz\n",
      "old shape: (87, 512, 512), new_shape: [ 87 472 472], old_spacing: [np.float64(2.5), np.float64(0.7324219942092896), np.float64(0.7324219942092896)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 6512\n",
      "4 10000\n",
      "5 2112\n",
      "6 2751\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_009.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_010.nii.gz\n",
      "old shape: (99, 512, 512), new_shape: [ 99 515 515], old_spacing: [np.float64(2.5), np.float64(0.7988280057907104), np.float64(0.7988280057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 8949\n",
      "4 10000\n",
      "5 2058\n",
      "6 3296\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (99, 512, 512), new_shape: [ 99 513 513], old_spacing: [np.float64(2.5), np.float64(0.7949219942092896), np.float64(0.7949219942092896)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2743\n",
      "6 2895\n",
      "7 13795\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_011.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_012.nii.gz\n",
      "old shape: (100, 512, 512), new_shape: [100 601 601], old_spacing: [np.float64(2.5), np.float64(0.9316409826278687), np.float64(0.9316409826278687)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 2603\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2712\n",
      "6 3344\n",
      "7 10377\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (75, 512, 512), new_shape: [ 90 479 479], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 5793\n",
      "4 10000\n",
      "5 1720\n",
      "6 2256\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_013.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_014.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_015.nii.gz\n",
      "old shape: (48, 512, 512), new_shape: [ 96 593 593], old_spacing: [np.float64(5.0), np.float64(0.9199219942092896), np.float64(0.9199219942092896)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2524\n",
      "6 2486\n",
      "7 10495\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (108, 512, 512), new_shape: [130 579 579], old_spacing: [np.float64(3.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 1805\n",
      "6 4977\n",
      "7 12880\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (101, 512, 512), new_shape: [101 630 630], old_spacing: [np.float64(2.5), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 1262\n",
      "6 3663\n",
      "7 12616\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_016.nii.gz\n",
      "old shape: (83, 512, 512), new_shape: [ 83 611 611], old_spacing: [np.float64(2.5), np.float64(0.9472659826278687), np.float64(0.9472659826278687)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 3624\n",
      "6 3943\n",
      "7 14006\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_017.nii.gz\n",
      "old shape: (90, 512, 512), new_shape: [ 90 529 529], old_spacing: [np.float64(2.5), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9545\n",
      "4 10000\n",
      "5 2835\n",
      "6 3491\n",
      "7 12435\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_018.nii.gz\n",
      "old shape: (77, 512, 512), new_shape: [ 77 559 559], old_spacing: [np.float64(2.5), np.float64(0.8671879768371582), np.float64(0.8671879768371582)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_019.nii.gz\n",
      "1 10000\n",
      "2 10000\n",
      "3 4409\n",
      "4 10000\n",
      "6 133\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (94, 512, 512), new_shape: [ 94 568 568], old_spacing: [np.float64(2.5), np.float64(0.8808590173721313), np.float64(0.8808590173721313)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2293\n",
      "6 3044\n",
      "7 11233\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_020.nii.gz\n",
      "old shape: (58, 512, 512), new_shape: [116 630 630], old_spacing: [np.float64(5.0), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 3964\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 4396\n",
      "6 5574\n",
      "7 14482\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_021.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_022.nii.gz\n",
      "old shape: (84, 512, 512), new_shape: [ 84 466 466], old_spacing: [np.float64(2.5), np.float64(0.7226560115814209), np.float64(0.7226560115814209)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2997\n",
      "6 4043\n",
      "7 11549\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (75, 512, 512), new_shape: [ 90 477 477], old_spacing: [np.float64(3.0), np.float64(0.740234375), np.float64(0.740234375)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 7234\n",
      "4 10000\n",
      "5 2448\n",
      "6 3054\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_023.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_024.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_025.nii.gz\n",
      "old shape: (51, 512, 512), new_shape: [102 456 456], old_spacing: [np.float64(5.0), np.float64(0.70703125), np.float64(0.70703125)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2426\n",
      "6 2938\n",
      "7 10142\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (49, 512, 512), new_shape: [ 98 500 500], old_spacing: [np.float64(5.0), np.float64(0.7753909826278687), np.float64(0.7753909826278687)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9526\n",
      "4 10000\n",
      "5 2492\n",
      "6 3622\n",
      "7 16262\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_026.nii.gz\n",
      "old shape: (60, 512, 512), new_shape: [120 525 525], old_spacing: [np.float64(5.0), np.float64(0.8144530057907104), np.float64(0.8144530057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 3006\n",
      "6 4332\n",
      "7 12967\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (90, 512, 512), new_shape: [ 90 501 501], old_spacing: [np.float64(2.5), np.float64(0.7773439884185791), np.float64(0.7773439884185791)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2424\n",
      "6 3773\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_027.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_028.nii.gz\n",
      "old shape: (62, 512, 512), new_shape: [ 74 442 442], old_spacing: [np.float64(3.0), np.float64(0.685546875), np.float64(0.685546875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 1571\n",
      "2 10000\n",
      "3 4881\n",
      "4 10000\n",
      "5 1725\n",
      "6 1704\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (87, 512, 512), new_shape: [ 87 520 520], old_spacing: [np.float64(2.5), np.float64(0.8066409826278687), np.float64(0.8066409826278687)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 7411\n",
      "4 10000\n",
      "5 2327\n",
      "6 3779\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_029.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_030.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_031.nii.gz\n",
      "old shape: (44, 512, 512), new_shape: [ 88 629 629], old_spacing: [np.float64(5.0), np.float64(0.9760000109672546), np.float64(0.9760000109672546)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "old shape: (79, 512, 512), new_shape: [158 503 503], old_spacing: [np.float64(5.0), np.float64(0.7792969942092896), np.float64(0.7792969942092896)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "3 8658\n",
      "4 10000\n",
      "1 10000\n",
      "7 11260\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 5020\n",
      "6 6996\n",
      "7 10686\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (93, 512, 512), new_shape: [112 584 584], old_spacing: [np.float64(3.0), np.float64(0.90625), np.float64(0.90625)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 4362\n",
      "6 6325\n",
      "7 15022\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_032.nii.gz\n",
      "old shape: (101, 512, 512), new_shape: [101 597 597], old_spacing: [np.float64(2.5), np.float64(0.9257810115814209), np.float64(0.9257810115814209)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 5554\n",
      "6 6034\n",
      "7 12542\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_033.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_034.nii.gz\n",
      "old shape: (75, 512, 512), new_shape: [ 90 465 465], old_spacing: [np.float64(3.0), np.float64(0.720703125), np.float64(0.720703125)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 4128\n",
      "4 10000\n",
      "5 3017\n",
      "6 3649\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (52, 512, 512), new_shape: [104 514 514], old_spacing: [np.float64(5.0), np.float64(0.796875), np.float64(0.796875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 7876\n",
      "4 10000\n",
      "5 2996\n",
      "6 3156\n",
      "7 15937\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_035.nii.gz\n",
      "old shape: (109, 512, 512), new_shape: [109 540 540], old_spacing: [np.float64(2.5), np.float64(0.8378909826278687), np.float64(0.8378909826278687)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 6386\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2605\n",
      "6 3471\n",
      "7 11797\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_036.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_037.nii.gz\n",
      "old shape: (47, 512, 512), new_shape: [ 94 453 453], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 2936\n",
      "6 2404\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (112, 512, 512), new_shape: [134 479 479], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 2765\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 1026\n",
      "6 3652\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_038.nii.gz\n",
      "old shape: (81, 512, 512), new_shape: [ 81 494 494], old_spacing: [np.float64(2.5), np.float64(0.765625), np.float64(0.765625)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 5482\n",
      "2 10000\n",
      "3 7870\n",
      "4 10000\n",
      "5 2432\n",
      "6 2278\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_039.nii.gz\n",
      "old shape: (87, 512, 512), new_shape: [ 87 494 494], old_spacing: [np.float64(2.5), np.float64(0.765625), np.float64(0.765625)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 1470\n",
      "6 2313\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_040.nii.gz\n",
      "old shape: (85, 512, 512), new_shape: [ 85 495 495], old_spacing: [np.float64(2.5), np.float64(0.7675780057907104), np.float64(0.7675780057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 5304\n",
      "4 10000\n",
      "5 2396\n",
      "6 3031\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_041.nii.gz\n",
      "old shape: (93, 512, 512), new_shape: [ 93 504 504], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 7100\n",
      "2 10000\n",
      "3 7805\n",
      "4 10000\n",
      "5 1646\n",
      "6 1700\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_042.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_043.nii.gz\n",
      "old shape: (100, 512, 512), new_shape: [100 495 495], old_spacing: [np.float64(2.5), np.float64(0.7675780057907104), np.float64(0.7675780057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 7986\n",
      "4 10000\n",
      "5 3159\n",
      "6 3881\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_044.nii.gz\n",
      "old shape: (95, 512, 512), new_shape: [ 95 503 503], old_spacing: [np.float64(2.5), np.float64(0.7792969942092896), np.float64(0.7792969942092896)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "5 3534\n",
      "6 4635\n",
      "7 11372\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (85, 512, 512), new_shape: [ 85 499 499], old_spacing: [np.float64(2.5), np.float64(0.7734379768371582), np.float64(0.7734379768371582)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 8008\n",
      "4 10000\n",
      "5 1861\n",
      "6 3097\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_045.nii.gz\n",
      "old shape: (86, 512, 512), new_shape: [103 431 431], old_spacing: [np.float64(3.0), np.float64(0.66796875), np.float64(0.66796875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 5275\n",
      "2 10000\n",
      "3 9531\n",
      "4 10000\n",
      "5 2701\n",
      "6 3365\n",
      "7 11012\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_046.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_047.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_048.nii.gz\n",
      "old shape: (64, 512, 512), new_shape: [ 77 452 452], old_spacing: [np.float64(3.0), np.float64(0.701171875), np.float64(0.701171875)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 3834\n",
      "4 10000\n",
      "5 1138\n",
      "6 2285\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (102, 512, 512), new_shape: [102 579 579], old_spacing: [np.float64(2.5), np.float64(0.8984379768371582), np.float64(0.8984379768371582)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1f9aaf9000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 8519\n",
      "4 10000\n",
      "5 2354\n",
      "6 2421\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (86, 512, 512), new_shape: [103 504 504], old_spacing: [np.float64(3.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fd013915000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9858\n",
      "4 10000\n",
      "5 2253\n",
      "6 3463\n",
      "7 13102\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_049.nii.gz\n",
      "/workspace/nnUNet_raw/Dataset500_AbdominalCTMultiOrgan/labelsTr/ct_050.nii.gz\n",
      "old shape: (101, 512, 512), new_shape: [101 562 562], old_spacing: [np.float64(2.5), np.float64(0.8710939884185791), np.float64(0.8710939884185791)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f7ba90e5000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 9331\n",
      "4 10000\n",
      "5 1826\n",
      "6 2275\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "old shape: (48, 512, 512), new_shape: [ 96 495 495], old_spacing: [np.float64(5.0), np.float64(0.7675780057907104), np.float64(0.7675780057907104)], new_spacing: [2.5, 0.7939454913139343, 0.7939454913139343], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7f1ea160d000>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "2 10000\n",
      "3 6446\n",
      "4 10000\n",
      "5 1830\n",
      "6 2058\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "10 10000\n",
      "11 10000\n",
      "12 10000\n",
      "Starting training for configuration 3d_fullres (fold all)...\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-11-15 05:49:39.075275: Using torch.compile...\n",
      "2025-11-15 05:49:41.152205: do_dummy_2d_data_aug: True\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 192], 'median_image_size_in_voxels': [97.0, 512.0, 512.0], 'spacing': [2.5, 0.7939454913139343, 0.7939454913139343], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset500_AbdominalCTMultiOrgan', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [2.5, 0.7939454913139343, 0.7939454913139343], 'original_median_shape_after_transp': [87, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 163.5000762939453, 'median': 168.0, 'min': 0.0, 'percentile_00_5': 24.0, 'percentile_99_5': 255.0, 'std': 44.6243782043457}}} \n",
      "\n",
      "2025-11-15 05:49:49.150047: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-11-15 05:49:49.251622: \n",
      "2025-11-15 05:49:49.275575: Epoch 0\n",
      "2025-11-15 05:49:49.301292: Current learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n",
      "/usr/local/lib/python3.10/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  output = output[crop_slices].contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n",
      "Using class weights in RobustFocalLoss\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not cfg.skip_preprocessing:\n",
    "    plans_identifier = run_planning_and_preprocessing(cfg, active_configurations)\n",
    "else:\n",
    "    plans_identifier = cfg.plans_identifier\n",
    "    if cfg.log_to_stdout:\n",
    "        print(\"Skipping planning & preprocessing.\")\n",
    "\n",
    "model_directories: Dict[str, Path] = {}\n",
    "for configuration in active_configurations:\n",
    "    model_dir = build_model_output_dir(dataset_name, cfg.trainer_class, plans_identifier, configuration)\n",
    "    model_directories[configuration] = model_dir\n",
    "    if cfg.skip_training:\n",
    "        if cfg.log_to_stdout:\n",
    "            print(f\"Skipping training for configuration {configuration}.\")\n",
    "        continue\n",
    "    if cfg.log_to_stdout:\n",
    "        print(f\"Starting training for configuration {configuration} (fold {cfg.fold})...\")\n",
    "    run_training_stage(cfg, dataset_name, configuration, plans_identifier)\n",
    "\n",
    "model_directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a625fda",
   "metadata": {},
   "source": [
    "## Inference & Evaluation\n",
    "Generate validation metrics and export test predictions (optionally as PNG slices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Inference & Evaluation Stage (Trainer-aware version)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "results: Dict[Tuple[str, str], object] = {}\n",
    "file_ending = \".nii.gz\"\n",
    "plans_identifier = cfg.plans_identifier\n",
    "\n",
    "if cfg.log_to_stdout:\n",
    "    print(\"\\n[INFO] Starting inference stage...\")\n",
    "    print(\"[INFO] Skipping planning & preprocessing (using pre-trained folds).\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Build model path dynamically based on trainer variant\n",
    "# ----------------------------------------------------------------------\n",
    "dataset_tag = f\"Dataset{cfg.dataset_id:03d}_{cfg.dataset_name}\"\n",
    "trainer_name = cfg.trainer_class\n",
    "config_tag = cfg.configurations[0] if cfg.configurations else \"3d_fullres\"\n",
    "\n",
    "model_dir = (\n",
    "    Path(cfg.nnunet_results)\n",
    "    / dataset_tag\n",
    "    / f\"{trainer_name}__{cfg.plans_identifier}__{config_tag}\"\n",
    ")\n",
    "\n",
    "fold_dir = model_dir / f\"fold_{cfg.fold}\"\n",
    "if not fold_dir.exists():\n",
    "    raise FileNotFoundError(f\"[ERROR] Expected trained fold directory does not exist: {fold_dir}\")\n",
    "\n",
    "if cfg.log_to_stdout:\n",
    "    print(f\"[INFO] Using model directory: {model_dir}\")\n",
    "    print(f\"[INFO] Using fold directory: {fold_dir}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Validation Inference\n",
    "# ----------------------------------------------------------------------\n",
    "if not cfg.skip_validation_inference and case_splits.get(\"val\"):\n",
    "    val_inputs = build_inference_input_lists(dataset_dir / \"imagesTr\", case_splits[\"val\"], file_ending)\n",
    "\n",
    "    val_output_dir = (\n",
    "        (cfg.prediction_output / config_tag / cfg.trainer_variant / \"val\")\n",
    "        if cfg.prediction_output\n",
    "        else fold_dir / \"pipeline_val_predictions\"\n",
    "    )\n",
    "\n",
    "    if cfg.log_to_stdout:\n",
    "        print(f\"[INFO] Running validation inference...\")\n",
    "        print(f\"[INFO] Output directory: {val_output_dir}\")\n",
    "\n",
    "    run_inference(\n",
    "        model_dir=model_dir,\n",
    "        fold=cfg.fold,\n",
    "        inputs=val_inputs,\n",
    "        output_dir=val_output_dir,\n",
    "        device=cfg.device,\n",
    "        checkpoint_name=cfg.checkpoint_name,\n",
    "        save_probabilities=cfg.save_probabilities,\n",
    "        overwrite=cfg.overwrite,\n",
    "        num_preprocess_workers=cfg.inference_preprocess_workers,\n",
    "        num_export_workers=cfg.inference_export_workers,\n",
    "    )\n",
    "\n",
    "    summary_file = val_output_dir / \"summary.json\"\n",
    "    summary = compute_validation_metrics(\n",
    "        predictions_dir=val_output_dir,\n",
    "        dataset_dir=dataset_dir,\n",
    "        plans_identifier=plans_identifier,\n",
    "        output_filename=summary_file,\n",
    "    )\n",
    "    results[(config_tag, f\"{cfg.trainer_variant}_validation\")] = summary\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Test Inference\n",
    "# ----------------------------------------------------------------------\n",
    "if not cfg.skip_test_inference and case_splits.get(\"test\"):\n",
    "    test_inputs = build_inference_input_lists(dataset_dir / \"imagesTs\", case_splits[\"test\"], file_ending)\n",
    "\n",
    "    test_output_dir = (\n",
    "        (cfg.prediction_output / config_tag / cfg.trainer_variant / \"test\")\n",
    "        if cfg.prediction_output\n",
    "        else fold_dir / \"pipeline_test_predictions\"\n",
    "    )\n",
    "\n",
    "    if cfg.log_to_stdout:\n",
    "        print(f\"[INFO] Running test inference...\")\n",
    "        print(f\"[INFO] Output directory: {test_output_dir}\")\n",
    "\n",
    "    run_inference(\n",
    "        model_dir=model_dir,\n",
    "        fold=cfg.fold,\n",
    "        inputs=test_inputs,\n",
    "        output_dir=test_output_dir,\n",
    "        device=cfg.device,\n",
    "        checkpoint_name=cfg.checkpoint_name,\n",
    "        save_probabilities=cfg.save_probabilities,\n",
    "        overwrite=cfg.overwrite,\n",
    "        num_preprocess_workers=cfg.inference_preprocess_workers,\n",
    "        num_export_workers=cfg.inference_export_workers,\n",
    "    )\n",
    "\n",
    "    # Export PNGs for visual verification\n",
    "    if cfg.export_test_pngs:\n",
    "        png_root = cfg.png_output_root or (cfg.data_root / \"test_labels\")\n",
    "        png_root = Path(png_root)\n",
    "        if len(active_configurations) > 1 and cfg.png_output_root is None:\n",
    "            png_root = png_root / config_tag / cfg.trainer_variant\n",
    "        export_predictions_to_png(test_output_dir, png_root, case_folder_map)\n",
    "        if cfg.log_to_stdout:\n",
    "            print(f\"[INFO] Test PNG segmentations saved to {png_root}\")\n",
    "\n",
    "    # Bounding box prompts (if applicable)\n",
    "    if cfg.bounding_box_prompts:\n",
    "        bbox_target = test_output_dir / \"test_bboxes.json\"\n",
    "        if not bbox_target.exists():\n",
    "            parse_bbox_prompts(cfg.bounding_box_prompts, bbox_target)\n",
    "\n",
    "    results[(config_tag, f\"{cfg.trainer_variant}_test\")] = str(test_output_dir)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Display summary\n",
    "# ----------------------------------------------------------------------\n",
    "if cfg.log_to_stdout:\n",
    "    print(\"\\n============================\")\n",
    "    print(\"Inference Summary:\")\n",
    "    for key, val in results.items():\n",
    "        print(f\" - {key}: {val}\")\n",
    "    print(\"============================\\n\")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec98c1-849b-4e6f-92e5-787927194c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
